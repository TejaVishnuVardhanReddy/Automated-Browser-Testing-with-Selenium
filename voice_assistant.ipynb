import pyttsx3
import speech_recognition as sr
import webbrowser
import wikipedia
import time
import random
import pystray
from pystray import MenuItem as item
from PIL import Image, ImageDraw
import tkinter as tk
import threading
import sys
import pyautogui
import requests
from bs4 import BeautifulSoup

# Initialize the speech engine
engine = pyttsx3.init()
engine.setProperty('rate', 150)  # Set speech rate
engine.setProperty('volume', 1.0)  # Set volume

# Change voice to a little girl voice (check available voices in your system)
voices = engine.getProperty('voices')
for voice in voices:
    if "female" in voice.name.lower():
        engine.setProperty('voice', voice.id)  # Select a female voice (try out which one sounds like a little girl)

# Store the links globally to be able to open them later
links = []

# Function to speak a message
def speak(message):
    print("Speaking:", message)
    engine.say(message)
    engine.runAndWait()

# Function to take voice input
def listen():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        recognizer.adjust_for_ambient_noise(source, duration=0.5)
        audio = recognizer.listen(source)

    try:
        print("Recognizing...")
        query = recognizer.recognize_google(audio, language='en-US')
        print(f"You said: {query}")
        return query.lower()
    except Exception as e:
        return None

# Function to process commands and perform actions
def process_command(command):
    global links
    
    if command:
        if 'open google' in command:
            speak("Opening Google...")
            webbrowser.open("https://www.google.com")
        elif 'search' in command:
            search_query = command.replace("search", "").strip()
            speak(f"Searching for {search_query} on Google...")
            webbrowser.open(f"https://www.google.com/search?q={search_query}")
        elif 'open youtube' in command:
            speak("Opening YouTube...")
            webbrowser.open("https://www.youtube.com")
        elif 'open the first link' in command:
            if links:
                speak(f"Opening the first link: {links[0]}")
                webbrowser.open(links[0])
            else:
                speak("No links available to open.")
        elif 'open the second link' in command:
            if len(links) > 1:
                speak(f"Opening the second link: {links[1]}")
                webbrowser.open(links[1])
            else:
                speak("No second link available.")
        elif 'click on the first link' in command:
            speak("Which link, Sir?")
            query = listen()
            if query and 'first link' in query:
                speak("Clicking on the first link...")
                pyautogui.click(200, 300)  # Coordinates for the first link
            else:
                speak("Sorry, I didn't understand.")
        elif 'click on the second link' in command:
            speak("Which link, Sir?")
            query = listen()
            if query and 'second link' in query:
                speak("Clicking on the second link...")
                pyautogui.click(200, 400)  # Coordinates for the second link
            else:
                speak("Sorry, I didn't understand.")
        elif 'scroll down' in command:
            speak("Scrolling down...")
            pyautogui.scroll(-200)  # Scroll down by 200 units
        elif 'scroll up' in command:
            speak("Scrolling up...")
            pyautogui.scroll(200)  # Scroll up by 200 units
        elif 'click on the first video' in command:
            speak("Clicking on the first video...")
            pyautogui.click(200, 300)  # Coordinates for the first video
        elif 'click on the second video' in command:
            speak("Clicking on the second video...")
            pyautogui.click(200, 400)  # Coordinates for the second video
        elif 'stop' in command:
            speak("Goodbye!")
            print("Voice assistant stopped.")
            exit()
        else:
            speak("Sorry, I didn't understand that. Please try again.")

# Function to handle the system tray icon
def on_quit(icon, item):
    icon.stop()

def setup_tray_icon():
    # Create the tray icon
    icon_image = Image.new("RGBA", (64, 64), (0, 0, 0, 0))
    draw = ImageDraw.Draw(icon_image)
    draw.ellipse((10, 10, 54, 54), fill="black", outline="white")
    icon = pystray.Icon("Assistant", icon_image, "Voice Assistant", menu=pystray.Menu(item('Quit', on_quit)))
    icon.run()

# Function to show the microphone window on desktop
def show_mic_window():
    # Create a window
    window = tk.Tk()
    window.title("Voice Assistant")
    window.geometry("200x200")

    # Add a label showing the microphone is listening
    label = tk.Label(window, text="Listening...", font=("Arial", 20))
    label.pack(pady=50)

    # Run the window in a separate thread to avoid blocking
    window.mainloop()

# Function to extract all links from a webpage
def extract_links_from_page(url):
    global links
    page = requests.get(url)
    soup = BeautifulSoup(page.text, 'html.parser')
    
    # Find all anchor tags
    anchors = soup.find_all('a')
    links = [anchor.get('href') for anchor in anchors if anchor.get('href') and 'http' in anchor.get('href')]
    print(f"Links extracted: {links}")

# Main function to combine everything
def start_assistant():
    # Start the system tray icon
    tray_thread = threading.Thread(target=setup_tray_icon)
    tray_thread.daemon = True
    tray_thread.start()

    # Show the microphone window
    mic_thread = threading.Thread(target=show_mic_window)
    mic_thread.daemon = True
    mic_thread.start()

    # Greet the user
    speak("Assistant is ready! How can I assist you today?")

    # Extract links from Google
    extract_links_from_page('https://www.google.com')

    # Continuous listening loop
    while True:
        command = listen()  # Listen for the command
        if command:
            process_command(command)  # Process the command

if __name__ == "__main__":
    start_assistant()
